# Related Work
* RL
  * [Universal Planning Networks](https://arxiv.org/pdf/1804.00645.pdf)  
  Learn representations, specify distance-based rewards to reach new target states for model-free reinforcement learning, resulting in substantially more effective learning when solving new tasks described via image-based goals.
  * [Learning by Playing â€“ Solving Sparse Reward Tasks from Scratch](https://arxiv.org/pdf/1802.10567.pdf)  
  Extension to HER, deals also with sparse rewards.
  * [Hindsight Experience Replay](https://arxiv.org/pdf/1707.01495.pdf)  
  Using multiple goals to accelerate learning.
  * [Organizing Experience: A Deeper Look at Replay Mechanisms for Sample-based Planning in Continuous State Domains](https://www.ijcai.org/proceedings/2018/0666.pdf)
  * [Selective Experience Replay for Lifelong Learning](https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/viewFile/16054/16703)
* Catastrophic Forgetting
  * [Overcoming catastrophic forgetting in neural networks](https://arxiv.org/abs/1612.00796)
  * [Overcoming Catastrophic Forgetting by Incremental Moment Matching](https://papers.nips.cc/paper/7051-overcoming-catastrophic-forgetting-by-incremental-moment-matching.pdf)  
Details how to overcome catastrophic forgetting, when learning online with neural nets.
  * [Progress & Compress: A scalable framework for continual learning](https://arxiv.org/abs/1805.06370)  
  Makes use of distillation and also gives reinforcement learning tasks as examples
  * [Measuring Catastrophic Forgetting in Neural Networks](https://arxiv.org/pdf/1708.02072.pdf)
  * [Overcoming catastrophic forgetting with hard attention to the task](https://arxiv.org/abs/1801.01423)
  * [Continual Lifelong Learning with Neural Networks: A Review](https://arxiv.org/pdf/1802.07569.pdf)
  * [Continual Learning Through Synaptic Intelligence](https://arxiv.org/pdf/1703.04200.pdf)
